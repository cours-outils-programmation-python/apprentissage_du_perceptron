Dans ce TP réalisé dans le cadre du cours d’apprentissage machine, nous avons commencé par concevoir un pipeline de traitement des données permettant de nettoyer la base, effectuer des jointures pour enrichir les données, et vérifier que les colonnes sont du bon type. Si ce n’était pas le cas, nous avons effectué les conversions nécessaires pour s’assurer de la cohérence des données.

Dans la deuxième partie, nous avons utilisé le jeu de données Fashion MNIST, intégré dans Keras (https://keras.io/api/datasets/fashion_mnist/), qui contient des images en niveaux de gris représentant divers articles de mode tels que des vêtements, des chaussures et des sacs à main. Notre objectif était d’entraîner un classifieur capable de reconnaître ces objets à partir de leurs images, en explorant différentes architectures de réseaux de neurones profonds.

Nous avons ainsi construit quatre modèles : un PMC (Perceptron Multi-Couches) classique dont les hyperparamètres ont été optimisés par validation croisée ; un réseau de neurones convolutif simple (CNN) ; un CNN avec augmentation de données à l’aide de l’outil ImageDataGenerator de Keras (https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) ; et enfin un modèle basé sur le réseau VGG16 pré-entraîné (https://keras.io/api/applications/vgg/), dans une logique de transfert d’apprentissage visant à améliorer la performance du modèle.

En conclusion, nous avons dressé un tableau comparatif des performances (accuracy sur les données de test) et des temps d’entraînement de chaque modèle, puis généré une visualisation graphique pour mieux illustrer ces comparaisons. Notons que l’entraînement, en particulier du modèle VGG16, est très gourmand en ressources, rendant son exécution sur un simple processeur local difficile, voire impossible. C’est pourquoi nous avons utilisé l’accélération matérielle par GPU disponible sur Google Colab.
